{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "687a29e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv2ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv2-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv2Processor, LayoutLMv2ForTokenClassification\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load LayoutLM model and processor\n",
    "processor = LayoutLMv2Processor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n",
    "model = LayoutLMv2ForTokenClassification.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b4b4f5-13f6-450c-9967-9e650f503f2e",
   "metadata": {},
   "source": [
    "The warning above is not relevant for our particular usecase, since we are not using the model to make predictions or inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498b2cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Transform PDF into list of images for each page\n",
    "pdf = \"medical_files/medicare_doc.pdf\"\n",
    "all_images = convert_from_path(pdf, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27502e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from parser.image_processing import process_image_in_segments\n",
    "import pytesseract\n",
    "import torch\n",
    "\n",
    "\n",
    "def image_to_text(image):\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "\n",
    "def process_image_with_layout(image):\n",
    "    image = image.convert(\"RGB\")\n",
    "    encoding = processor(image, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    \n",
    "    # post-process outputs (e.g., get tokena dn bounding boxes)\n",
    "    tokens = processor.tokenizer.convert_ids_to_tokens( encoding[\"input_ids\"][0].tolist() )\n",
    "    boxes = encoding[\"bbox\"][0].tolist()\n",
    "    \n",
    "    return tokens, boxes\n",
    "\n",
    "\n",
    "def segment_image(image, processor, max_tokens=512):\n",
    "    width, height = image.size\n",
    "    segment_size = height // 2\n",
    "    \n",
    "    segments = list()\n",
    "    for top in range(0, height, segment_size):\n",
    "        box = (0, top, width, top + segment_size)\n",
    "        segment = image.crop(box)\n",
    "        \n",
    "        tokens = processor(segment, return_tensors=\"pt\")\n",
    "        \n",
    "        if tokens[\"input_ids\"].size(1) > max_tokens:\n",
    "            yield segment_image(segment, processor, max_tokens)\n",
    "        else:\n",
    "            yield segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21962386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Medicare Doc - page 2\n",
      "Text: Medicare strives to improve access to affordable t...truncated...\n",
      "bbox: [[0, 0, 0, 0], [91, 408, 171, 429], [178, 408, 235, 429], [178, 408, 235, 429], [242, 409, 259, 429], [267, 408, 339, 432], [346, 413, 404, 429], [411, 409, 428, 429], [435, 407, 527, 429], [534, 409, 631, 429]]...truncated...\n",
      "Tokens: ['[CLS]', 'medicare', 'strive', '##s', 'to', 'improve', 'access', 'to', 'affordable', 'treatments']...truncated...\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# Create and save pdf dataset to disk\n",
    "data = {\n",
    "    \"text\": [i[\"text\"] for i in structured_data], \n",
    "    \"bbox\": [i[\"bbox\"] for i in structured_data],\n",
    "    \"tokens\": [i[\"tokens\"] for i in structured_data],\n",
    "    \"title\": [f\"Medicare Doc - page {i['page_number']}\" for i in structured_data]\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "# dataset.save_to_disk(dataset_path)\n",
    "\n",
    "print(f\"Title: {data['title'][1]}\")\n",
    "print(f\"Text: {data['text'][1][0:50]}...truncated...\")\n",
    "print(f\"bbox: {data['bbox'][1][0:10]}...truncated...\")\n",
    "print(f\"Tokens: {data['tokens'][1][0:10]}...truncated...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea3f162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jermoljupiter/PycharmProjects/HealthiParse/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875af793f3e245338bd8e129d5f3ec94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'bbox', 'tokens', 'title', 'embeddings'],\n",
      "    num_rows: 4\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "def embed_text(text_data):\n",
    "    embeddings = embedding_model.embed_documents([text_data[\"text\"]])[0]\n",
    "    return {\"embeddings\": embeddings}\n",
    "\n",
    "dataset = dataset.map(embed_text)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e35d9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cbc81be6204f078b63384214c7da22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e7ea34ba3d4d0aba26f211f233bc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the FAISS index\n",
    "dimension = len(dataset[0][\"embeddings\"])  # dimension of embeddings\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.vstack(dataset[\"embeddings\"]))\n",
    "index_path = \"test_medicare_index\"\n",
    "faiss.write_index(index, index_path)\n",
    "\n",
    "# Save the index to disk\n",
    "dataset.add_faiss_index(column=\"embeddings\")\n",
    "dataset_path = \"test_medicare_dataset\"\n",
    "# Drop the FAISS index before saving the dataset to disk\n",
    "dataset.drop_index(\"embeddings\")\n",
    "dataset.save_to_disk(dataset_path)\n",
    "# dataset.add_faiss_index(column=\"embeddings\")\n",
    "# dataset.get_index(\"embeddings\").save(index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e61442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e609f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'meaical equipment penef#it, tTnat INSULIN Is Coverea unaer Meqicare Fart B. YOU WONT\\npay more than $35 for a month’s supply and the Medicare deductible no longer\\napplies. Go to pages 39 and 88.\\n\\nRecommended adult vaccines are also now available at no cost to you. Go to page 50.\\n\\nChanges to telehealth coverage\\n\\nYou can still get telehealth services at any location in the U.S., including your home,\\nuntil the end of 2024. After that, you must be in an office or medical facility located in\\na rural area to get most telehealth services. There are some exceptions, like for mental\\nhealth services. Go to page 51.\\n\\nManaging and treating chronic pain\\nMedicare now covers monthly services to treat chronic pain if you’ve been living with it\\nfor more than 3 months. Go to page 34.\\n\\nBetter mental health care\\n\\nMedicare now covers intensive outpatient program services provided by hospitals,\\ncommunity mental health centers, and other locations if you need mental health care.\\nGo to pages 46-47.\\n\\nMore times to sign up for Medicare\\n\\nIf you recently lost Cor will soon lose) Medicaid, you may be able to sign up for\\nMedicare or change your current Medicare coverage. There are other special situations\\nthat allow you to sign up for Medicare. Go to page 18.\\n\\nCOVID-19 care\\nMedicare continues to cover the COVID-19 vaccine, and several tests and treatments to\\nkeep you and others safe. Go to page 37.\\n', 'page_number': 2, 'tokens': ['[CLS]', 'me', '##ai', '##cal', 'equipment', 'pen', '##ef', '#', 'it', ',', 'tt', '##nat', 'insulin', 'is', 'cover', '##ea', 'una', '##er', 'me', '##qi', '##care', 'far', '##t', 'b', '.', 'you', 'won', '##t', 'pay', 'more', 'than', '$', '35', 'for', 'a', 'month', '’', 's', 'supply', 'and', 'the', 'medicare', 'de', '##du', '##ct', '##ible', 'no', 'longer', 'applies', '.', 'go', 'to', 'pages', '39', 'and', '88', '.', 'recommended', 'adult', 'vaccines', 'are', 'also', 'now', 'available', 'at', 'no', 'cost', 'to', 'you', '.', 'go', 'to', 'page', '50', '.', 'changes', 'to', 'tel', '##eh', '##eal', '##th', 'coverage', 'you', 'can', 'still', 'get', 'tel', '##eh', '##eal', '##th', 'services', 'at', 'any', 'location', 'in', 'the', 'u', '.', 's', '.', ',', 'including', 'your', 'home', ',', 'until', 'the', 'end', 'of', '202', '##4', '.', 'after', 'that', ',', 'you', 'must', 'be', 'in', 'an', 'office', 'or', 'medical', 'facility', 'located', 'in', 'a', 'rural', 'area', 'to', 'get', 'most', 'tel', '##eh', '##eal', '##th', 'services', '.', 'there', 'are', 'some', 'exceptions', ',', 'like', 'for', 'mental', 'health', 'services', '.', 'go', 'to', 'page', '51', '.', 'managing', 'and', 'treating', 'chronic', 'pain', 'medicare', 'now', 'covers', 'monthly', 'services', 'to', 'treat', 'chronic', 'pain', 'if', 'you', '’', 've', 'been', 'living', 'with', 'it', 'for', 'more', 'than', '3', 'months', '.', 'go', 'to', 'page', '34', '.', 'better', 'mental', 'health', 'care', 'medicare', 'now', 'covers', 'intensive', 'out', '##patient', 'program', 'services', 'provided', 'by', 'hospitals', ',', 'community', 'mental', 'health', 'centers', ',', 'and', 'other', 'locations', 'if', 'you', 'need', 'mental', 'health', 'care', '.', 'go', 'to', 'pages', '46', '-', '47', '.', 'more', 'times', 'to', 'sign', 'up', 'for', 'medicare', 'if', 'you', 'recently', 'lost', 'co', '##r', 'will', 'soon', 'lose', ')', 'med', '##ica', '##id', ',', 'you', 'may', 'be', 'able', 'to', 'sign', 'up', 'for', 'medicare', 'or', 'change', 'your', 'current', 'medicare', 'coverage', '.', 'there', 'are', 'other', 'special', 'situations', 'that', 'allow', 'you', 'to', 'sign', 'up', 'for', 'medicare', '.', 'go', 'to', 'page', '18', '.', 'co', '##vid', '-', '19', 'care', 'medicare', 'continues', 'to', 'cover', 'the', 'co', '##vid', '-', '19', 'vaccine', ',', 'and', 'several', 'tests', 'and', 'treatments', 'to', 'keep', 'you', 'and', 'others', 'safe', '.', 'go', 'to', 'page', '37', '.', '[SEP]'], 'bbox': [[0, 0, 0, 0], [91, 0, 158, 17], [91, 0, 158, 17], [91, 0, 158, 17], [166, 0, 263, 20], [271, 0, 337, 19], [271, 0, 337, 19], [271, 0, 337, 19], [271, 0, 337, 19], [271, 0, 337, 19], [344, 0, 379, 17], [344, 0, 379, 17], [387, 0, 441, 17], [449, 1, 460, 16], [467, 0, 538, 17], [467, 0, 538, 17], [547, 0, 598, 17], [547, 0, 598, 17], [606, 0, 686, 17], [606, 0, 686, 17], [606, 0, 686, 17], [694, 0, 729, 17], [694, 0, 729, 17], [737, 0, 753, 16], [737, 0, 753, 16], [762, 0, 792, 17], [800, 0, 849, 17], [800, 0, 849, 17], [91, 35, 121, 55], [129, 35, 174, 50], [181, 29, 219, 50], [227, 28, 259, 53], [227, 28, 259, 53], [267, 29, 291, 50], [302, 35, 306, 50], [314, 29, 383, 50], [314, 29, 383, 50], [314, 29, 383, 50], [391, 29, 449, 55], [456, 29, 488, 50], [496, 29, 524, 50], [532, 29, 612, 50], [619, 29, 714, 50], [619, 29, 714, 50], [619, 29, 714, 50], [619, 29, 714, 50], [722, 35, 743, 50], [751, 29, 807, 54], [90, 63, 157, 88], [90, 63, 157, 88], [165, 63, 189, 84], [196, 64, 213, 84], [221, 69, 273, 88], [281, 63, 302, 84], [309, 63, 341, 84], [348, 63, 375, 84], [348, 63, 375, 84], [90, 108, 226, 129], [233, 108, 278, 129], [285, 109, 361, 129], [368, 114, 395, 129], [403, 108, 437, 129], [445, 114, 481, 129], [488, 108, 565, 129], [573, 110, 588, 129], [597, 114, 617, 129], [624, 110, 661, 129], [668, 110, 685, 129], [693, 114, 729, 134], [693, 114, 729, 134], [736, 109, 761, 129], [768, 110, 785, 129], [793, 114, 836, 133], [844, 109, 870, 129], [844, 109, 870, 129], [90, 166, 175, 194], [182, 168, 202, 190], [209, 166, 309, 190], [209, 166, 309, 190], [209, 166, 309, 190], [209, 166, 309, 190], [317, 172, 407, 194], [90, 203, 122, 223], [130, 208, 160, 223], [168, 202, 196, 223], [204, 204, 232, 227], [239, 202, 327, 223], [239, 202, 327, 223], [239, 202, 327, 223], [239, 202, 327, 223], [334, 202, 406, 223], [413, 204, 429, 223], [436, 208, 467, 228], [475, 202, 545, 223], [553, 202, 566, 223], [573, 202, 601, 223], [609, 202, 647, 226], [609, 202, 647, 226], [609, 202, 647, 226], [609, 202, 647, 226], [609, 202, 647, 226], [655, 202, 734, 227], [742, 208, 782, 228], [789, 202, 842, 226], [789, 202, 842, 226], [91, 236, 126, 257], [134, 236, 162, 257], [169, 236, 201, 257], [209, 236, 226, 257], [232, 236, 282, 257], [232, 236, 282, 257], [232, 236, 282, 257], [289, 236, 335, 257], [341, 236, 380, 259], [341, 236, 380, 259], [387, 242, 419, 261], [427, 237, 470, 257], [478, 236, 499, 257], [506, 236, 520, 256], [527, 242, 547, 257], [555, 236, 604, 257], [611, 242, 629, 257], [637, 236, 705, 257], [713, 236, 771, 261], [779, 236, 844, 257], [852, 236, 865, 256], [90, 275, 98, 291], [107, 269, 145, 291], [153, 275, 190, 291], [197, 271, 214, 291], [222, 271, 250, 294], [258, 271, 301, 291], [308, 269, 395, 291], [308, 269, 395, 291], [308, 269, 395, 291], [308, 269, 395, 291], [403, 270, 479, 291], [403, 270, 479, 291], [487, 269, 537, 291], [544, 275, 571, 291], [578, 275, 626, 291], [633, 270, 733, 294], [633, 270, 733, 294], [742, 269, 769, 291], [776, 269, 801, 291], [808, 269, 867, 291], [91, 303, 144, 324], [151, 304, 227, 324], [151, 304, 227, 324], [235, 304, 259, 324], [266, 305, 283, 324], [291, 309, 335, 328], [342, 304, 362, 324], [342, 304, 362, 324], [91, 361, 186, 388], [194, 361, 230, 384], [237, 361, 315, 388], [324, 361, 397, 384], [405, 361, 446, 388], [91, 396, 171, 418], [179, 402, 215, 418], [222, 402, 279, 418], [288, 396, 360, 422], [366, 397, 438, 418], [445, 398, 462, 418], [469, 398, 511, 418], [518, 396, 583, 418], [591, 397, 627, 421], [635, 396, 645, 417], [651, 397, 709, 422], [651, 397, 709, 422], [651, 397, 709, 422], [717, 396, 760, 418], [768, 396, 813, 421], [820, 396, 857, 417], [865, 397, 875, 417], [90, 430, 114, 451], [122, 436, 167, 451], [173, 430, 212, 451], [220, 431, 229, 451], [237, 430, 307, 451], [237, 430, 307, 451], [315, 431, 339, 451], [346, 432, 363, 451], [371, 436, 414, 455], [422, 431, 448, 451], [422, 431, 448, 451], [91, 489, 152, 511], [159, 488, 226, 511], [235, 488, 296, 511], [304, 494, 345, 511], [91, 524, 171, 545], [179, 530, 215, 545], [222, 530, 279, 545], [288, 524, 365, 545], [372, 524, 464, 549], [372, 524, 464, 549], [472, 530, 548, 549], [556, 524, 627, 545], [635, 524, 713, 549], [722, 524, 742, 549], [750, 524, 832, 549], [750, 524, 832, 549], [90, 558, 191, 583], [198, 557, 257, 579], [266, 557, 319, 579], [327, 559, 396, 581], [327, 559, 396, 581], [404, 557, 436, 579], [443, 557, 490, 579], [498, 557, 577, 579], [585, 557, 594, 578], [601, 564, 632, 583], [641, 557, 683, 579], [692, 557, 751, 579], [760, 557, 812, 579], [820, 564, 862, 579], [820, 564, 862, 579], [90, 592, 114, 613], [121, 593, 138, 613], [146, 597, 198, 616], [206, 592, 264, 613], [206, 592, 264, 613], [206, 592, 264, 613], [206, 592, 264, 613], [91, 651, 138, 673], [146, 649, 200, 673], [207, 651, 227, 673], [235, 649, 274, 677], [283, 656, 307, 677], [314, 649, 342, 673], [350, 649, 440, 673], [91, 685, 101, 706], [107, 691, 138, 711], [147, 685, 217, 711], [225, 685, 256, 706], [263, 686, 287, 709], [263, 686, 287, 709], [294, 685, 321, 706], [329, 691, 371, 706], [380, 685, 420, 709], [380, 685, 420, 709], [428, 685, 512, 709], [428, 685, 512, 709], [428, 685, 512, 709], [428, 685, 512, 709], [519, 691, 550, 711], [559, 691, 595, 711], [603, 685, 623, 706], [630, 685, 667, 706], [674, 687, 691, 706], [698, 686, 733, 710], [742, 691, 763, 710], [770, 685, 794, 706], [91, 719, 171, 740], [178, 725, 196, 740], [203, 719, 268, 744], [275, 725, 314, 744], [321, 721, 385, 740], [393, 719, 474, 740], [481, 725, 567, 744], [481, 725, 567, 744], [575, 719, 625, 740], [632, 725, 659, 740], [666, 719, 713, 740], [720, 719, 780, 744], [788, 719, 873, 740], [90, 752, 124, 774], [131, 752, 177, 774], [184, 759, 215, 778], [223, 754, 240, 774], [247, 753, 282, 778], [290, 759, 311, 778], [319, 752, 343, 774], [350, 752, 435, 774], [350, 752, 435, 774], [443, 753, 467, 774], [475, 754, 492, 774], [500, 759, 543, 778], [550, 753, 571, 774], [550, 753, 571, 774], [90, 811, 184, 834], [90, 811, 184, 834], [90, 811, 184, 834], [90, 811, 184, 834], [192, 817, 233, 834], [91, 846, 171, 868], [178, 847, 264, 868], [271, 848, 288, 868], [296, 852, 344, 868], [351, 846, 379, 868], [386, 847, 471, 868], [386, 847, 471, 868], [386, 847, 471, 868], [386, 847, 471, 868], [479, 847, 550, 870], [479, 847, 550, 870], [557, 846, 590, 868], [597, 846, 658, 868], [666, 848, 707, 868], [715, 846, 747, 868], [754, 848, 851, 868], [859, 848, 876, 868], [91, 880, 132, 905], [139, 886, 170, 906], [178, 880, 210, 901], [218, 880, 273, 901], [280, 880, 320, 901], [280, 880, 320, 901], [328, 881, 352, 901], [360, 882, 376, 901], [384, 886, 428, 905], [435, 881, 458, 901], [435, 881, 458, 901], [1000, 1000, 1000, 1000]]}, {'text': '', 'page_number': 2, 'tokens': ['[CLS]', '[SEP]'], 'bbox': [[0, 0, 0, 0], [1000, 1000, 1000, 1000]]}, {'text': \"Medicare strives to improve access to affordable treatments to keep you healthy.\\nCheck out what’s new this year to help you manage your health.\\n\\nIf you have Medicare drug coverage (Part D) and your drug costs are high enough\\nto reach the catastrophic coverage phase, you don’t have to pay a copayment\\n\\nor coinsurance. Extra Helo—a program that helps cover your Part D drug costs—\\nexpanded to cover more drug costs for certain people with limited resources and\\nincome. Go to pages 83 and 92.\\n\\nCoinsurance amounts for some Part B-covered drugs may be less if a prescription\\ndrug’s price increased higher than the rate of inflation. Go to page 40.\\n\\nYour Medicare drug plan can't charge you more than $35 for a one-month supply of\\neach insulin product Part D covers, and you don’t have to pay a deductible for it. Go to\\npage 88.\\n\\nIf you take insulin through a traditional pump that’s covered under Medicare’s durable\\n\", 'page_number': 2, 'tokens': ['[CLS]', 'medicare', 'strive', '##s', 'to', 'improve', 'access', 'to', 'affordable', 'treatments', 'to', 'keep', 'you', 'healthy', '.', 'check', 'out', 'what', '’', 's', 'new', 'this', 'year', 'to', 'help', 'you', 'manage', 'your', 'health', '.', 'if', 'you', 'have', 'medicare', 'drug', 'coverage', '(', 'part', 'd', ')', 'and', 'your', 'drug', 'costs', 'are', 'high', 'enough', 'to', 'reach', 'the', 'catastrophic', 'coverage', 'phase', ',', 'you', 'don', '’', 't', 'have', 'to', 'pay', 'a', 'copa', '##yme', '##nt', 'or', 'coins', '##urance', '.', 'extra', 'he', '##lo', '—', 'a', 'program', 'that', 'helps', 'cover', 'your', 'part', 'd', 'drug', 'costs', '—', 'expanded', 'to', 'cover', 'more', 'drug', 'costs', 'for', 'certain', 'people', 'with', 'limited', 'resources', 'and', 'income', '.', 'go', 'to', 'pages', '83', 'and', '92', '.', 'coins', '##urance', 'amounts', 'for', 'some', 'part', 'b', '-', 'covered', 'drugs', 'may', 'be', 'less', 'if', 'a', 'prescription', 'drug', '’', 's', 'price', 'increased', 'higher', 'than', 'the', 'rate', 'of', 'inflation', '.', 'go', 'to', 'page', '40', '.', 'your', 'medicare', 'drug', 'plan', 'can', \"'\", 't', 'charge', 'you', 'more', 'than', '$', '35', 'for', 'a', 'one', '-', 'month', 'supply', 'of', 'each', 'insulin', 'product', 'part', 'd', 'covers', ',', 'and', 'you', 'don', '’', 't', 'have', 'to', 'pay', 'a', 'de', '##du', '##ct', '##ible', 'for', 'it', '.', 'go', 'to', 'page', '88', '.', 'if', 'you', 'take', 'insulin', 'through', 'a', 'traditional', 'pump', 'that', '’', 's', 'covered', 'under', 'medicare', '’', 's', 'durable', '[SEP]'], 'bbox': [[0, 0, 0, 0], [91, 408, 171, 429], [178, 408, 235, 429], [178, 408, 235, 429], [242, 409, 259, 429], [267, 408, 339, 432], [346, 413, 404, 429], [411, 409, 428, 429], [435, 407, 527, 429], [534, 409, 631, 429], [639, 409, 656, 429], [664, 408, 705, 432], [712, 413, 743, 432], [752, 408, 819, 432], [752, 408, 819, 432], [90, 442, 145, 462], [152, 443, 180, 462], [188, 442, 244, 462], [188, 442, 244, 462], [188, 442, 244, 462], [252, 447, 287, 462], [294, 442, 325, 462], [332, 447, 370, 466], [377, 443, 393, 462], [402, 442, 438, 466], [446, 447, 477, 466], [485, 447, 556, 466], [563, 447, 602, 466], [610, 442, 668, 462], [610, 442, 668, 462], [91, 541, 101, 562], [107, 548, 138, 567], [147, 542, 187, 563], [195, 542, 275, 563], [283, 542, 323, 567], [331, 548, 413, 567], [421, 542, 464, 566], [421, 542, 464, 566], [472, 542, 491, 566], [472, 542, 491, 566], [498, 542, 530, 563], [538, 548, 577, 567], [584, 542, 625, 567], [632, 543, 678, 563], [686, 548, 712, 563], [720, 542, 757, 567], [764, 542, 831, 567], [90, 577, 107, 597], [115, 576, 162, 597], [169, 576, 197, 597], [204, 576, 315, 600], [323, 581, 405, 600], [413, 576, 468, 600], [413, 576, 468, 600], [476, 581, 507, 600], [515, 576, 560, 597], [515, 576, 560, 597], [515, 576, 560, 597], [568, 576, 608, 597], [615, 577, 632, 597], [640, 581, 671, 600], [678, 581, 686, 596], [694, 577, 794, 600], [694, 577, 794, 600], [694, 577, 794, 600], [90, 615, 107, 630], [115, 610, 226, 630], [115, 610, 226, 630], [115, 610, 226, 630], [234, 610, 279, 630], [288, 610, 354, 634], [288, 610, 354, 634], [288, 610, 354, 634], [288, 610, 354, 634], [362, 615, 438, 634], [445, 610, 480, 630], [488, 610, 533, 634], [541, 615, 589, 630], [596, 615, 636, 634], [643, 610, 679, 630], [687, 610, 698, 630], [706, 610, 746, 634], [754, 611, 816, 630], [754, 611, 816, 630], [90, 643, 178, 668], [185, 645, 202, 664], [210, 649, 258, 664], [266, 649, 311, 664], [318, 643, 358, 668], [366, 645, 412, 664], [419, 643, 444, 664], [451, 643, 511, 664], [520, 643, 580, 668], [587, 643, 623, 664], [632, 643, 690, 664], [699, 649, 784, 664], [791, 643, 823, 664], [91, 677, 159, 698], [91, 677, 159, 698], [167, 677, 191, 698], [198, 678, 215, 698], [223, 683, 275, 702], [282, 677, 304, 698], [311, 677, 343, 698], [351, 677, 376, 698], [351, 677, 376, 698], [90, 722, 200, 743], [90, 722, 200, 743], [207, 723, 284, 743], [292, 721, 316, 743], [323, 727, 370, 743], [378, 722, 413, 742], [421, 722, 513, 743], [421, 722, 513, 743], [421, 722, 513, 743], [521, 722, 571, 746], [578, 727, 615, 746], [622, 722, 643, 743], [651, 722, 682, 743], [690, 721, 699, 742], [706, 727, 715, 742], [723, 722, 829, 746], [90, 755, 144, 780], [90, 755, 144, 780], [90, 755, 144, 780], [152, 755, 195, 780], [203, 755, 287, 776], [296, 755, 351, 780], [358, 755, 396, 776], [404, 755, 431, 776], [439, 757, 472, 776], [479, 755, 497, 776], [504, 755, 579, 776], [504, 755, 579, 776], [587, 755, 611, 776], [618, 757, 635, 776], [643, 761, 687, 780], [693, 755, 721, 776], [693, 755, 721, 776], [90, 850, 130, 870], [138, 849, 219, 870], [226, 849, 267, 874], [275, 849, 311, 874], [318, 850, 363, 870], [318, 850, 363, 870], [318, 850, 363, 870], [370, 849, 433, 874], [440, 854, 472, 874], [480, 854, 526, 870], [533, 849, 574, 870], [581, 848, 614, 873], [581, 848, 614, 873], [621, 849, 645, 870], [652, 855, 660, 870], [668, 849, 767, 870], [668, 849, 767, 870], [668, 849, 767, 870], [774, 849, 833, 874], [840, 849, 857, 870], [90, 883, 131, 904], [139, 883, 193, 904], [202, 883, 272, 908], [280, 884, 315, 903], [323, 884, 335, 903], [342, 889, 404, 906], [342, 889, 404, 906], [411, 883, 444, 904], [451, 889, 482, 908], [491, 883, 536, 904], [491, 883, 536, 904], [491, 883, 536, 904], [543, 883, 584, 904], [591, 884, 608, 904], [615, 889, 646, 908], [653, 889, 662, 903], [670, 883, 765, 904], [670, 883, 765, 904], [670, 883, 765, 904], [670, 883, 765, 904], [772, 882, 796, 904], [804, 883, 818, 903], [804, 883, 818, 903], [826, 883, 849, 904], [857, 884, 874, 904], [91, 922, 134, 941], [141, 917, 167, 937], [141, 917, 167, 937], [91, 961, 101, 982], [107, 968, 138, 987], [146, 962, 183, 983], [191, 962, 245, 983], [253, 962, 323, 987], [331, 968, 339, 982], [346, 962, 436, 983], [445, 968, 495, 987], [503, 962, 551, 982], [503, 962, 551, 982], [503, 962, 551, 982], [558, 962, 629, 983], [637, 962, 688, 983], [696, 962, 789, 983], [696, 962, 789, 983], [696, 962, 789, 983], [797, 962, 864, 983], [1000, 1000, 1000, 1000]]}, {'text': '.\\n\\nHEALY,\\noF He\\nss %,\\n\\nx\\n\\nRog\\n\\nCEMS SERVICES\\n', 'page_number': 1, 'tokens': ['[CLS]', '.', 'healy', ',', 'of', 'he', 'ss', '%', ',', 'x', 'ro', '##g', 'ce', '##ms', 'services', '[SEP]'], 'bbox': [[0, 0, 0, 0], [621, 894, 623, 897], [617, 879, 625, 905], [617, 879, 625, 905], [620, 908, 630, 916], [619, 866, 632, 879], [627, 918, 640, 928], [629, 854, 641, 866], [629, 854, 641, 866], [636, 925, 644, 931], [639, 848, 655, 858], [639, 848, 655, 858], [797, 897, 909, 937], [797, 897, 909, 937], [912, 931, 933, 934], [1000, 1000, 1000, 1000]]}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def retrieve_pages(index, query, embedding_model, page_mapping, k=5):\n",
    "    query_embeddings = embedding_model.embed_documents([query])\n",
    "    query_embedding = np.array(query_embeddings[0]).reshape(1, -1)\n",
    "    distance, indices = index.search(query_embedding, k)\n",
    "    valid_indices = [idx for idx in indices[0] if idx != -1]\n",
    "    pages = [page_mapping[idx] for idx in valid_indices]\n",
    "    return pages\n",
    "\n",
    "\n",
    "# Save the page mapping for retrieval\n",
    "page_mapping = {i: entry for i, entry in enumerate(structured_data)}\n",
    "    \n",
    "query = \"Better Mental health care\"\n",
    "relevant_pages = retrieve_pages(index, query, embedding_model, page_mapping)\n",
    "print(relevant_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffe436f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "Some weights of the model checkpoint at facebook/rag-sequence-nq were not used when initializing RagSequenceForGeneration: ['rag.question_encoder.question_encoder.bert_model.pooler.dense.bias', 'rag.question_encoder.question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RagSequenceForGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RagSequenceForGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "\n",
    "# Initialize RAG model\n",
    "\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\")\n",
    "\n",
    "retriever = RagRetriever.from_pretrained(\n",
    "    \"facebook/rag-sequence-nq\", \n",
    "    index_name=\"custom\",\n",
    "    passages_path=dataset_path,\n",
    "    index_path=index_path,\n",
    ")\n",
    "\n",
    "rag_model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0efba0fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from BioMistral-7B.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = hub\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = hub\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 32\n",
      "llama_new_context_with_model: n_ubatch   = 32\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     5.06 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token + ' ' }}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '10000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'hub'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import torch\n",
    "\n",
    "\n",
    "# Initialize BioMistral LLM\n",
    "llm = LlamaCpp(\n",
    "    model_path= \"BioMistral-7B.Q4_K_M.gguf\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024,\n",
    "    top_p=1\n",
    ")\n",
    "\n",
    "def calculate_token_length(text, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    return inputs.input_ids.size(1)\n",
    "\n",
    "\n",
    "def format_context(relevant_pages, tokenizer, max_length):\n",
    "    print(\"Start check of segment size....\")\n",
    "    context = list()\n",
    "\n",
    "    for page in relevant_pages:\n",
    "        text = page[\"text\"]\n",
    "        bbox = page[\"bbox\"]\n",
    "        tokens = page[\"tokens\"]\n",
    "        \n",
    "    if len(tokens):\n",
    "        context_entry = f\"Text: {text}\\nTokens: {tokens}\\nBbox: {bbox}\\n\"\n",
    "        \n",
    "        \n",
    "    combined_context = \"\\n\".join(context)\n",
    "    return combined_context\n",
    "\n",
    "def process_chunk(chunk, question):\n",
    "    prompt = f\"Context: {chunk}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "    t_size = calculate_token_length(prompt, tokenizer)\n",
    "    print(f\"The size of this prompt is {t_size} >>>>\")\n",
    "    response = llm(prompt)\n",
    "    return response\n",
    "\n",
    "\n",
    "def generate_answer(question, n_docs=5):\n",
    "    # Tokenize the question\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\")\n",
    "    # Generate question hidden states using the RAG model's question encoder\n",
    "    outputs = rag_model.question_encoder(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask)\n",
    "    question_hidden_states = outputs[0].detach().numpy()\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    relevant_pages = retrieve_pages(index, question, embedding_model, page_mapping, k=n_docs)\n",
    "    \n",
    "    # Calculate the maximum length for the context\n",
    "    max_context_length = 512\n",
    "    \n",
    "    # Segment the context\n",
    "    context_segments = segment_context(relevant_pages, tokenizer, max_context_length)\n",
    "    \n",
    "    # # Process each chunk and gather responses\n",
    "    # combined_response = []\n",
    "    # for chunk in context_segments:\n",
    "    #     response = process_chunk(chunk, question)\n",
    "    #     combined_response.append(response)\n",
    "    \n",
    "    # # Combine the responses to form the final answer\n",
    "    # final_answer = \"\\n\".join(combined_response)\n",
    "    # return final_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e2a6552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segment_context' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the maximum amount of money I can pay for a one-month supply of insulin?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "Cell \u001b[0;32mIn[10], line 57\u001b[0m, in \u001b[0;36mgenerate_answer\u001b[0;34m(question, n_docs)\u001b[0m\n\u001b[1;32m     54\u001b[0m max_context_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Segment the context\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m context_segments \u001b[38;5;241m=\u001b[39m \u001b[43msegment_context\u001b[49m(relevant_pages, tokenizer, max_context_length)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'segment_context' is not defined"
     ]
    }
   ],
   "source": [
    "question = \"What is the maximum amount of money I can pay for a one-month supply of insulin?\"\n",
    "answer = generate_answer(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96cff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec129c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
